<!-- https://blog.csdn.net/2401_87546826/article/details/143617657 -->

参考：https://www.doubao.com/thread/wab0634dd3eb46c8e


使用 FileReader 对文件进行分片处理，每次将分片转为ArrayBuffer，再通过SparkMD5库的增量哈希计算功能逐片计算文件的MD5，最后将计算好的哈希值回传给主线程

> 300G 文件用 SparkMD5 增量哈希（30M 分片）的大致用时：机械硬盘（HDD）约 40~80 分钟，固态硬盘（SSD）约 10~30 分钟—— 核心耗时瓶颈不是 SparkMD5 的哈希计算，而是「文件分片读取的磁盘 IO 速度」（占总耗时的 80%+），哈希计算本身耗时可忽略。


```js
// 核心逻辑（极简）
const spark = new SparkMD5.ArrayBuffer();
FileReader.onload = (e) => {
  spark.append(e.target.result); // 直接传ArrayBuffer，无需额外处理
  // 继续读下一分片...
  if (所有分片读完) spark.end(); // 生成最终MD5
};
```

## 用 Web Worker 避免主线程阻塞
用 Web Worker 避免主线程阻塞大文件哈希计算（如 300G 需计算 10000 个分片）会占用主线程，导致页面卡顿（如按钮点击无响应）。优化方式：将 “分片读取 + SparkMD5 计算” 逻辑放入 Web Worker，主线程仅负责进度展示和上传控制。

```js
// 主线程
const worker = new Worker('hash-worker.js');
worker.postMessage({ file, chunkSize: 30 * 1024 * 1024 });
worker.onmessage = (e) => {
//   if (e.data.progress) updateProgress(e.data.progress); // 更新进度
  if (e.data.md5) console.log('整体MD5：', e.data.md5); // 接收最终结果
};
```

worker线程：
```js
// hash-worker.js（Web Worker）
importScripts('https://cdn.jsdelivr.net/npm/spark-md5@3.0.2/spark-md5.min.js');
self.onmessage = async (e) => {
  const { file, chunkSize } = e.data;
  const spark = new SparkMD5.ArrayBuffer();  
  let offset = 0;
  while (offset < file.size) {
    const chunk = file.slice(offset, offset + chunkSize);
    const arrayBuffer = await new Promise(resolve => {
        // TODO:重要！！！
      const reader = new FileReader();
      reader.onload = (e) => resolve(e.target.result);
      reader.readAsArrayBuffer(chunk);
    });
    spark.append(arrayBuffer);
    offset += chunkSize;
    self.postMessage({ progress: (offset / file.size) * 100 }); // 发送进度
  }
  self.postMessage({ md5: spark.end() }); // 发送最终MD5
};
```

## 增加读取中断机制
增加读取中断机制若用户在计算 MD5 过程中取消上传（如关闭页面、切换文件），需中断 FileReader 读取，避免无效 IO 和内存占用：
```js
let reader = null; // 保存当前FileReader实例
const abortHashCalculation = () => {
  if (reader) reader.abort(); // 中断当前读取
  spark.reset(); // 重置SparkMD5状态
  offset = 0; // 重置偏移量
};

// 读取分片时保存实例
const readNextChunk = () => {
  reader = new FileReader(); // 重新赋值当前reader
  reader.onload = () => { /* ... */ };
  reader.readAsArrayBuffer(chunk);
};
```